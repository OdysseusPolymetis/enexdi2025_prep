{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/enexdi2025_prep/blob/main/2_word_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUKJJyV4EKwh"
      },
      "source": [
        "# <center>**Word Vectors**</center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Definition**"
      ],
      "metadata": {
        "id": "lrfpDSkzzK6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can try and imagine language as a cloud, with scattered points, where each point is a different word. The location of each point is dependent on the location of every other point in the cloud (eg. if two words share the same context, they should appear near one to another). As long as you can represent a point in space, it gets a computational representation : it becomes a vector in space, a direction. And it becomes possible to compute things from it."
      ],
      "metadata": {
        "id": "RPF5Vq2VzQUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo(\"ORstNrlG_2g\", width=512, height=288)"
      ],
      "metadata": {
        "id": "fMH5QvWSzXjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1FsTcOQ5LVgbDqkT5nm_gve5gZfQrZ8pV)"
      ],
      "metadata": {
        "id": "kkeuuYTFze23"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btSJGNjQEKwj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import glob\n",
        "import nltk\n",
        "\n",
        "from lxml import etree as ET\n",
        "import lxml.html\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ABC-DH/EnExDi2024/main/materials/3_NLP/auteurs.zip"
      ],
      "metadata": {
        "id": "s8-gi9VwSMEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/auteurs.zip\""
      ],
      "metadata": {
        "id": "k3JLxuWlS_jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt2CYBKmEKwl"
      },
      "outputs": [],
      "source": [
        "flaubert=\"auteurs/flaubert/\"\n",
        "balzac=\"auteurs/balzac/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG-aW6vOEKwp"
      },
      "outputs": [],
      "source": [
        "def strip_ns_prefix(tree):\n",
        "    query = \"descendant-or-self::*[namespace-uri()!='']\"\n",
        "    for element in tree.xpath(query):\n",
        "        element.tag = ET.QName(element).localname\n",
        "    return tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4tLGaUjEKwp"
      },
      "outputs": [],
      "source": [
        "if balzac != \"\":\n",
        "    files = glob.iglob(balzac + '/**/*.xml', recursive=True)\n",
        "    sentences = []\n",
        "\n",
        "    for filename in files:\n",
        "        print(filename)\n",
        "        parser = ET.XMLParser(remove_blank_text=True, resolve_entities=False, encoding='utf8')\n",
        "        tree = strip_ns_prefix(ET.parse(filename, parser))\n",
        "\n",
        "        words = tree.xpath(\".//wf/@lemma\")\n",
        "\n",
        "        sentence = []\n",
        "        for word in words:\n",
        "            if word != \".\":\n",
        "                sentence.append(word)\n",
        "            else:\n",
        "                sentences.append(sentence + [word])\n",
        "                sentence = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWKGOPhgEKwq"
      },
      "outputs": [],
      "source": [
        "print(len(sentences))\n",
        "print(sentences[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Xl4zaIEKwr"
      },
      "source": [
        "## Building a model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part, depending on the amount of data you intend to compute, may take some time (default : 8 minutes)"
      ],
      "metadata": {
        "id": "XLU6gj_Afxmk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RatPiNJ2EKws"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences, min_count=2, max_vocab_size=10000, negative=10, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4yuImONEKws"
      },
      "outputs": [],
      "source": [
        "model.wv.save(\"/content/model_balzac.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next cell is to be run only if you want to reload a saved model."
      ],
      "metadata": {
        "id": "nCOsjlH0QC48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "KeyedVectors.load(\"/content/model_balzac.bin\")\n",
        "wv = KeyedVectors.load(\"/content/model_balzac.bin\")\n",
        "\n",
        "model = Word2Vec(vector_size=wv.vector_size, min_count=1)\n",
        "model.wv = wv"
      ],
      "metadata": {
        "id": "QAktcdnKNPpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clnMDVgzEKws"
      },
      "outputs": [],
      "source": [
        "print(model.wv.index_to_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czf2ZjP9EKws"
      },
      "outputs": [],
      "source": [
        "#Paris is to France what London is to what ? model.wv.most_similar(positive=['Londres', 'France'], negative=['Paris'],topn=5)\n",
        "#King is to man what Queen is to what ? model.wv.most_similar(positive=['reine', 'homme'], negative=['roi'],topn=5)\n",
        "model.wv.most_similar(positive=['reine', 'homme'], negative=['roi'],topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('esprit',topn=20)"
      ],
      "metadata": {
        "id": "M3poyzGldb4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization with Tensorflow\n",
        "You can get a clearer visualization using the [online tensorflow visualizer](https://projector.tensorflow.org/). After this next cell, you'll get two files, one containing the vectors, the other their labels."
      ],
      "metadata": {
        "id": "dS_L_ZjGvDAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ABC-DH/EnExDi2024/main/materials/3_NLP/stopwords_fr.txt"
      ],
      "metadata": {
        "id": "ePwXdpLrU3JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops = open(\"/content/stopwords_fr.txt\", encoding=\"utf-8\").read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "hcgp0bLSU47L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/vecteurs.tsv\", 'w') as file_vectors, open(\"/content/metadonnees.tsv\", 'w') as file_metadata:\n",
        "    for word in model.wv.index_to_key:\n",
        "        file_vectors.write('\\t'.join([str(x) for x in model.wv[word]]) + \"\\n\")\n",
        "        file_metadata.write(word + \"\\n\")"
      ],
      "metadata": {
        "id": "IRRnV7TbVlI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}